{"cells":[{"cell_type":"markdown","metadata":{"id":"M2R0lWX-jzzl"},"source":["# LangGraph\n","\n","## 사전 준비 : 가상환경 구축 및 패키지 설치"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"0Ri5Xd5Ijzzm","executionInfo":{"status":"ok","timestamp":1746967203868,"user_tz":-540,"elapsed":29977,"user":{"displayName":"하호진","userId":"01408081046197671833"}},"outputId":"f76a5edb-c384-42c6-d20b-b220c74be4ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: google-generativeai 0.8.5\n","Uninstalling google-generativeai-0.8.5:\n","  Successfully uninstalled google-generativeai-0.8.5\n","Requirement already satisfied: langchain==0.3.24 in /usr/local/lib/python3.11/dist-packages (0.3.24)\n","Collecting langchain_core==0.3.55\n","  Downloading langchain_core-0.3.55-py3-none-any.whl.metadata (5.9 kB)\n","Collecting langchain_google_genai==2.1.3\n","  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n","Requirement already satisfied: httpx==0.28.1 in /usr/local/lib/python3.11/dist-packages (0.28.1)\n","Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (2.32.3)\n","Collecting langchain-tavily==0.1.5\n","  Downloading langchain_tavily-0.1.5-py3-none-any.whl.metadata (11 kB)\n","Collecting langgraph==0.3.31\n","  Downloading langgraph-0.3.31-py3-none-any.whl.metadata (7.9 kB)\n","Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.24) (0.3.8)\n","Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.24) (0.3.39)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.24) (2.11.4)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.24) (2.0.40)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.24) (6.0.2)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_core==0.3.55) (9.1.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain_core==0.3.55) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core==0.3.55) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain_core==0.3.55) (4.13.2)\n","Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai==2.1.3)\n","  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n","Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain_google_genai==2.1.3)\n","  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx==0.28.1) (4.9.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.28.1) (2025.4.26)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.28.1) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx==0.28.1) (3.10)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3) (2.4.0)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.11.14 in /usr/local/lib/python3.11/dist-packages (from langchain-tavily==0.1.5) (3.11.15)\n","Collecting mypy<2.0.0,>=1.15.0 (from langchain-tavily==0.1.5)\n","  Downloading mypy-1.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n","Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph==0.3.31)\n","  Downloading langgraph_checkpoint-2.0.25-py3-none-any.whl.metadata (4.6 kB)\n","Collecting langgraph-prebuilt<0.2,>=0.1.8 (from langgraph==0.3.31)\n","  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n","Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph==0.3.31)\n","  Downloading langgraph_sdk-0.1.66-py3-none-any.whl.metadata (1.8 kB)\n","Collecting xxhash<4.0.0,>=3.5.0 (from langgraph==0.3.31)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx==0.28.1) (0.16.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily==0.1.5) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily==0.1.5) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily==0.1.5) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily==0.1.5) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily==0.1.5) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily==0.1.5) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily==0.1.5) (1.20.0)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai==2.1.3) (2.24.2)\n","Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai==2.1.3) (2.38.0)\n","Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai==2.1.3) (1.26.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai==2.1.3) (5.29.4)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core==0.3.55) (3.0.0)\n","Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph==0.3.31)\n","  Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.3.31) (3.10.18)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.24) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.24) (0.23.0)\n","Collecting mypy_extensions>=1.0.0 (from mypy<2.0.0,>=1.15.0->langchain-tavily==0.1.5)\n","  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.24) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.24) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.24) (0.4.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.24) (3.2.1)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx==0.28.1) (1.3.1)\n","Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai==2.1.3) (1.70.0)\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai==2.1.3) (1.71.0)\n","Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai==2.1.3) (1.71.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai==2.1.3) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai==2.1.3) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai==2.1.3) (4.9.1)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai==2.1.3) (0.6.1)\n","Downloading langchain_core-0.3.55-py3-none-any.whl (434 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.1/434.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_google_genai-2.1.3-py3-none-any.whl (43 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_tavily-0.1.5-py3-none-any.whl (14 kB)\n","Downloading langgraph-0.3.31-py3-none-any.whl (145 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.2/145.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n","Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langgraph_checkpoint-2.0.25-py3-none-any.whl (42 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n","Downloading langgraph_sdk-0.1.66-py3-none-any.whl (47 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mypy-1.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (12.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n","Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: filetype, xxhash, ormsgpack, mypy_extensions, mypy, langgraph-sdk, langchain_core, langgraph-checkpoint, google-ai-generativelanguage, langgraph-prebuilt, langchain_google_genai, langgraph, langchain-tavily\n","  Attempting uninstall: langchain_core\n","    Found existing installation: langchain-core 0.3.56\n","    Uninstalling langchain-core-0.3.56:\n","      Successfully uninstalled langchain-core-0.3.56\n","  Attempting uninstall: google-ai-generativelanguage\n","    Found existing installation: google-ai-generativelanguage 0.6.15\n","    Uninstalling google-ai-generativelanguage-0.6.15:\n","      Successfully uninstalled google-ai-generativelanguage-0.6.15\n","Successfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain-tavily-0.1.5 langchain_core-0.3.55 langchain_google_genai-2.1.3 langgraph-0.3.31 langgraph-checkpoint-2.0.25 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.66 mypy-1.15.0 mypy_extensions-1.1.0 ormsgpack-1.9.1 xxhash-3.5.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]},"id":"9c561a4d979b4a9db1c0b5c8a169d890"}},"metadata":{}}],"source":["#1\n","\n","!pip uninstall -y google-generativeai\n","!pip install langchain==0.3.24 langchain_core==0.3.55 langchain_google_genai==2.1.3 httpx==0.28.1 requests==2.32.3 langchain-tavily==0.1.5 langgraph==0.3.31"]},{"cell_type":"markdown","metadata":{"id":"iBBagfYTjzzm"},"source":["## Tool Calling을 이용한 AI 에이전트 구현 방법"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"mZerj4V3jzzm","executionInfo":{"status":"ok","timestamp":1746967233336,"user_tz":-540,"elapsed":3276,"user":{"displayName":"하호진","userId":"01408081046197671833"}}},"outputs":[],"source":["# 2\n","\n","import os\n","import time\n","import operator\n","import uuid\n","from typing import  Annotated\n","from typing_extensions import TypedDict, Annotated\n","from pydantic import BaseModel, Field\n","\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, AnyMessage\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_tavily import TavilySearch, TavilyExtract\n","\n","from langgraph.types import Command\n","from langgraph.prebuilt import ToolNode\n","from langgraph.graph import StateGraph, START, END\n","from langgraph.checkpoint.memory import MemorySaver\n","\n","#환경 변수와 패키지 준비\n","from google.colab import userdata\n","os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n","os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gOGP8ij8jzzn","executionInfo":{"status":"ok","timestamp":1746967258911,"user_tz":-540,"elapsed":2284,"user":{"displayName":"하호진","userId":"01408081046197671833"}},"outputId":"695bb136-f8ed-4988-c4b3-33ee9fe8881f"},"outputs":[{"output_type":"stream","name":"stdout","text":["content='저는 구글에서 학습된 대규모 언어 모델입니다.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'models/gemini-2.5-flash-preview-04-17', 'safety_ratings': []} id='run-4e986a72-f25c-42f2-8689-316e3c5358f7-0' usage_metadata={'input_tokens': 7, 'output_tokens': 13, 'total_tokens': 314, 'input_token_details': {'cache_read': 0}}\n"]}],"source":["# 3\n","\n","# gemini 모델 정의\n","llm = ChatGoogleGenerativeAI(\n","    model=\"gemini-2.5-flash-preview-04-17\",\n","    temperature=0,\n","    max_retries=0,\n",")\n","\n","print(llm.invoke(\"너 이름이 뭐니?\"))"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"3mv7Oyjkjzzn","executionInfo":{"status":"ok","timestamp":1746967262011,"user_tz":-540,"elapsed":49,"user":{"displayName":"하호진","userId":"01408081046197671833"}}},"outputs":[],"source":["#4\n","\n","tavily_search_tool = TavilySearch(\n","    max_results=10,\n","    topic=\"general\",\n",")\n","\n","tavily_extract_tool = TavilyExtract()\n","\n","tools = [\n","    tavily_search_tool,\n","    tavily_extract_tool\n","]\n","\n","system_prompt = \"\"\"\n","당신은 한국어를 말하는 우수한 어시스턴트입니다. 회답에는 반드시 한국어로 대답해 주세요. 또 생각하는 과정도 출력해 주세요.\n","우리는 'tavily_search_tool'과 'tavily_extract_tool'이라는 두가지 툴을 가지고 있습니다.\n","tavily_search_tool은 구글 검색을 하고 상위 5개 URL과 개요를 가져오는 툴입니다. 어떤 웹사이트가 있는지를 알고자 할 경우에는 이곳을 이용합니다.\n","tavily_extract_tool은 URL을 지정하여 페이지의 내용을 추출하는 툴입니다. 특정 Web 사이트의 URL을 알고 있어 상세하게 내용을 추출하는 경우는 이쪽을 이용합니다.\n","적절하게 이용하여 사용자로부터 질문에 답변해 주세요.\n","\"\"\"\n","\n","# message 작성\n","message = [\n","    SystemMessage(content=system_prompt),\n","    MessagesPlaceholder(\"messages\"),\n","]\n","\n","# message 프롬프트 정의\n","prompt = ChatPromptTemplate.from_messages(message)\n","\n","#chain 정의\n","chain = prompt | llm.bind_tools(tools)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":266},"id":"fgSArk49jzzn","executionInfo":{"status":"ok","timestamp":1746967266104,"user_tz":-540,"elapsed":193,"user":{"displayName":"하호진","userId":"01408081046197671833"}},"outputId":"b1ac9a24-8e42-4116-f081-71ed49353d2e"},"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAANgAAAD5CAIAAADKsmwpAAAAAXNSR0IArs4c6QAAIABJREFUeJztnWdcFNf+xs9sZTu9dxAEUVQsEYxdY4uIBQsmdm8sNyFGk5jcxMSLxhtzjbEk1mgMKpYgxnLFht3EgoUmIEgvy1K2L9vm/2L9o9ksiLizZ5Y9348vdndmzu9Z9vHMmVN+B8NxHCAQsKHAFoBAAGREBFlARkSQAmREBClARkSQAmREBCmgwRbQEZqVuvoqtUKqU0i1Wi2uVVtBDxSTRaExMDaPxuZT3XzsYMshHdZkRLlEU5gpL86WSeo1PEc6m0dl82h8Rzqwhq5QvQ7UljQrpHI6k1L2WBEQwQnszgnszoWtiyxgVtGhrdfhN0/Wi6qanTwZgRFcr2AWbEWvhUqhe5otryhUVBWrosc7denFg60IPlZgxJw/xJeP1kW/7dRriANsLWZGUq+5eaq+WaEb9Y47i0uFLQcmZDfi5aNCOzbljXHOsIUQiKi6OW1b5ejZ7t5d2LC1QIPURjyfXOseYNc9RgBbiCU4vq3yzThnZ08mbCFwIK8R036sDO7JjYi2CRcaOL6tonuMfXBPW3yCIWk/4rW0Ov9wjk25EAAQt9T7j//VN9aqYQuBABmNmJ8ppdEpPYfYwxYCgYRPfTOOCkl7myIOMhrxytG63sNs0YUAAAzD/MM5N0/WwxZiaUhnxHsXGiNi+EyW7fZl9B7mkPunRCXXwRZiUchlRBzHy/IV0eM7c2dNexg0yeXBlSbYKiwKuYxYnCVnssglCQq+oezsm2LYKiwKuX71p9nygAiOhYN+8sknJ0+e7MCFI0aMqKqqIkARYHGp9s6M6hIlEYWTE3IZsalOE9jd0kbMy8vrwFU1NTVNTQTePUP6cMsLFMSVTzZIZESVXNcoVBP3mJKWlhYfHx8TEzN8+PCVK1fW1tYCAPr06VNVVfX1118PGTIEAKDT6bZv3z5x4sTo6OgxY8asX79eqXxWLY0YMeLgwYPvv//+gAEDrl27Nn78eADAhAkTPvroIyLUcvg0UYUtdSjipEFUpTqwvpSgwjMzM6OiolJTU8vLy7OyshYsWDBnzhwcx2tra6OiolJSUpqamnAc379/f//+/dPT00tLS2/dujV69OgNGzYYSnjrrbcmT578ww8/PHz4UKlUnjt3LioqKi8vTyaTESG4+qnyyPdlRJRMTkg0H1Eu0XH4RFWHRUVFTCbz7bffptFo3t7e69evr66uBgAIBAIAAJvNNrwYM2bMgAEDgoODAQC+vr6jRo26ceOGoQQMw+zs7N5//33DWw6HAwDg8/mGF2aHI6DKxTbUg0MiI+J6nEHYI3OfPn0wDFuwYEFsbGz//v09PT2dnJz+fpq9vf3p06eTkpKEQqFWq1UoFGz28xkxPXr0IEje36HSMIYdiRpOREOir8rm08R1GoIK9/f337t3r7e395YtWyZMmDBnzpzs7Oy/n7Zhw4bdu3fHx8fv2rXr4MGDcXFxLx7lci03HUHWpKXSMIuFgw6JjMjhU+USAm9GXbp0SUpKOn/+/I4dO6hUamJiolr9l6cBnU534sSJ2bNnjx071svLy9nZWSaTEaenbQhtqJAQEhmRzaM5utP1ekLG+7Ozsx89egQAoFKpUVFRixcvbmpqqq9/NqRrmGSg1+t1Op2hsQgAkMvlV69ebXv+AXGzE5oVOhcfG5qbSCIjAgDs2NTiLDkRJd+8eXP58uUXL16sqKjIz89PSUnx8PBwd3dnMplMJjMzMzM/Px/DsNDQ0FOnTlVUVBQWFiYmJsbExEgkkpKSEq1Wa1Qgn88HAFy/fr24uJgIwfn3pB7+1r0055UglxH9u3FKcggx4rx58+Li4jZt2jRlypSlS5fiOL5582YMwwAAc+bMuXDhwpIlS5RK5ZdffqnT6eLj41etWjV9+vSlS5e6u7u/++67QqHQqMCwsLDo6Ojvv//+22+/NbtanRavfKL07WpDKwfINUNbKdOeS66Nfc8LthDIPM2RlRcoB8W5wBZiOchVI7K4NAc3xkMbm3jyd27+Xm9rs9NJ1I9oIOZt5x2fFkUONj0xVqfTDR8+3OQhtVrNYDBMHgoICNi7d69ZZT5n3759+/btM3mIy+W29twdFhb2008/mTz0+K7E1cfO0c30d+mskOvWbODBlSYMwyMHmV7FLJVKTX7e3NzMYDAMzT4jKBQKQeMfhrhG3UAtaDQaOp1u8hCVSn2xq/xFTu2uGjzFhWdv+sLOChmNaPgxur0hsPyUMOjY7BcnVxuxhfELPK+m1tXXNMMWYlEuHRa6+9vZoAvJWyMahp4P/7d80CQXzyCb6E7LOCL07sKy2Tw4JK0RAQAYBZu+0vfWmfq82xLYWohFr8OPb6t0dGfYrAtJXSO2cPOUqCxPEf22c6fs4L1zriH/rnTIVBdbTnxjHUYEANRVNt88KeLwaZ5BrIAIDotj9bMBhOWqsnzF3XONPYfY9xvtSKHY0EQbk1iHEQ1UFCry70qfZstdfJgCZzqHT+PwaWw+Va+HrawdUDEgbtDIxToc4I/vSDl8WnAkp8cgezqDvK0jS2JNRmyh+qlSVKmWS7RyiZaCYQqZOSePKRSK0tLSsLAwM5YJAOA50HEc5wioPEe6dxCLIyDdUAJcrNKIhJKXl7d27drk5GTYQmwLdF9AkAJkRAQpQEY0BsMwX19f2CpsDmREY3AcLysrg63C5kBGNIElV+shDCAjmgDi4j2bBRnRGAzDnJ1tPUGj5UFGNAbHcZFIBFuFzYGMaAyFQgkICICtwuZARjRGr9c/ffoUtgqbAxkRQQqQEY3BMKwl6wjCYiAjGoPjuFhsW4nUyQAyogns7W10uyGIICOagNAs7QiTICMiSAEyojEYhnl52XoWKMuDjGgMjuOVlZWwVdgcyIgIUoCMaAyGYX5+frBV2BzIiMbgOF5aWgpbhc2BjIggBciIxqDZN1BARjQGzb6BAjIighQgIxqDlpNCARnRGLScFArIiAhSgIxoArSu2fIgI5oArWu2PMiIxlAoFG9vb9gqbA5kRGP0en1FRQVsFTYHMiKCFCAjGoNhmKOjI2wVNgcyojE4jjc0NMBWYXMgIxpDoVD8/f1hq7A5kBGN0ev1JSUlsFXYHMiIxqAaEQrIiMagGhEKyIjGUCgUV1dX2CpsDrThzzNmzJghk8kwDFOr1TKZzMHBAcOw5ubm9PR02NJsAlQjPmPMmDFCobCqqkokEqlUqurq6qqqKh7PdvettTDIiM+YPn26j4/Pi59gGDZ48GB4imwLZMRnMBiMiRMnUqnPN+D19fWdMmUKVFE2BDLic+Lj41uy3mAYNnToUA8PD9iibAVkxOcwGIzJkycbKkVfX9+pU6fCVmRDICP+hfj4eE9PT0N16ObmBluODWGV21frdXhTnUZcryGi6yl25KLLly8P7D25OFtu9sLpDMzJg8HmWeWfnVCsrx8x77Yk5w+JSqZzD2ApJObcu94CsHjU0jy5u5/dsGkuyI4vYmVGzPlDUpwlHzTFnULBYGvpOI01zVdTa+KWenH4yIvPsKY2YkGmtOiRfEi8h1W7EADg4M4cM8/7wDdo9fRzrMaIOI5n3RBHT+gko8AMO2rkEMd7FxthCyELVmNEpUzXKNQwWdR2nGsd8Bzo1cVK2CrIgtUYUdKgdfWxg63CnAic6FqNNTXQCcVqjIgBoJRqYaswJ3o9sLqnfuKwGiMiOjfIiAhSgIyIIAXIiAhSgIyIIAXIiAhSgIyIIAXIiAhSgIyIIAXIiAhSgIyIIAXIiAhSgIxoHo6nHVn/7VewVVgxyIjmoaAgD7YE66Yzr5nQ6XT7f9118eLZOpGQzxfERA/+x6IPWCwWAECr1f7408YLF8/qdNpBbw6PiR78xeoVqcfOOTg4arXa5AN7LmWcq62tdnFxmzolIXbCs3wPcZNHvpMwv1ZYcykjXalUdO/ea8Xyfzk5OScuX/TwYSYAID391MkTl9F+QR2gM9eIx347ePDQvnnzluzZlfLxytU3bl7Z/fO2lkMnT6UuWvjPn7btd3Z22b7zB0NCOgDA9h0/HD7ya8KMuXt2H546JWHrtu9On0kzXEWj0Q4d/sXfP/DQgZM/7z5SWPj41+TdAICkNRtDunQdNnRUWuoFDocD9UtbK525RhwxfEzfPgMCA4MBAN7evkOHjPrz9g3DofRzpwbGDBk/Lg4AMH/ektzcrMrKcsOeUyd+P5owc+5bb40HAHh7+RQWPj54aN+4sRMNF/r5BowZPQEA4Orq1q9vdH5+rmHLNCqNRmcwBAJ7qN/YiunMRhQI7M+dP/3dxiSRSKjVapVKBYvFNqzDqqgoGz82ruXMgQOHZt6/AwAoKirQarV9ot5oORQZGXX6TJpCoWCz2QCAwMAuLYd4PL5EKrH41+qcdGYjbtm64fyFMx9+sKpbRCSTwTyU8suljHQAgFwu12q1LDa75Uw+X2B4oVDIAQAffvQPDHu2YtWw7ruhsd5gRCaT+WII617WSiY6rRH1ev2Z/514Z9aCkSPHGj6Ry59t9Uin0wEAKpWq5WTp/1dsHA4XAPD5Z0mBAcEvlubqgvLgEEtnNqJOp2up6uRy+c1bVw2PI0wm09XV7XF+TsvJ169nGF4EBnah0+mNjQ2+g59tLNDU1IhhGIPBeGlE68qZQTY67VMzjUbrEhyafu5UZVVFUVHhZ/9K7N8/RiqVlJWVaLXawYNGXLly4VLGucqqin2/7KgTCQ1Xcbnc8eMn7ftlx6WMc1XVlfcf3F3x8ZL29FTzuLwnT/ILn+RrtZ1qqaHF6LRGBACsXPGlXqebNz9+TdKqSXHTF8xb6ubqvnjpu3Ui4dw57w16c9iG79YsXTZHKpPOmjkPAECj0QEAS977cGLs1J27Ns+eM3n9f1Z3j+j5+aqkl8aKi5suEtW9/8H8lgYA4pWwmiRMtaWqy8fqxi7wace5L0er1cpkUnt7B8Pb/b/uTj2ekpZ6wSyFt5MmofrabzUzP/W1ZFDS0plrxDY4cHDvzFkTLl+5UFlVcf3G5dTjKW+NGg9blE3TaR9W2iZh5ly1unn7jk0NDfWuLm7jxk58952FsEXZNDZqRBqNtnDBsoULlsEWgniGjd6aEWQDGRFBCpAREaQAGRFBCpAREaQAGRFBCpAREaQAGRFBCpAREaQAGRFBCqzGiFQa4DrSYaswJ3ocd3B/+XxbG8FqjOjkyXz6qFNN9RNVqhh2VvP3Jxqr+UNgGBYSxaspVcAWYjYaq9UB3djtONEmsBojAgCGxbtcO1arUnSGTXLuXRDRGCCwO8oJ8QyrmaFtoFmp259U2muYE9ee7uDKsCrtwLDleV2lSlShpDOwQZNcjh07NmXKFNiiSIGVGdHA7u8y2Jg3y44tFmnMXrhep1NrNHZ2hOz75+zJpDOxoB7c4J5cAMDdu3c///zz9PR0ImJZGbi1UVpaumnTJuLK/+qrr4YNG3br1i3iQryIRCLBcTwrK8sy4UiLNbURxWJxfn6+QCD44IMPCAqRm5v78OFDsVh88OBBgkIYwePxDMtYx40bJ5fLLROUhFiNEUUiUVxcXEBAgEAgIC7KoUOHysrKAAAFBQU3btwgLpAR/v7+e/bsKSoqEovFFgtKKqzDiEKhsKys7NKlS+3JuNBh8vLyMjMzDa9FIpHFKkUD7u7uPXr0wDBs2rRpCkXn6aVqJ1ZgxOXLl+M43rt3b6IDHThwoLa2tuVtbm6uJStFA3w+f+3atXfu3LFwXOiQ2og4jt+7dy82NtbNjfAcSLm5uS3VoQGxWJycnEx03L8THBw8ePBgAMDixYvVarXlBUCBvEa8f/++XC7v3r274Vchmv3799fW1ur1+pbnOADA48ePLRC6NRYsWLB48WKIAiwK1Gf2VsnKypo/fz6U0Lm5uQkJCVBCt8aZM2dgSyAcktaIjY2Nu3fvhhXdz88PVmiTuLq6vvPOO7BVEAvpjPjhhx8CAN58801YApRKpVAohBXdJFFRUf/+978BAOXl5bC1EAW5jHj06NG4uLh2nEggSqXSxcUFroa/4+/vDwAoKyv7/vvvYWshBHIZcejQoYMGDYKrQSQSETTQ/PrExMS4uLiUlJTAFmJ+SGFEtVo9ZMgQAICzszNsLUAsFnt5ecFW0SqzZs1yc3PLycl5scuzE0AKI+7bt+/y5cuwVTyjqKjIAt2WrwOLxQoLC5s7d25TUxNsLWYDshF1Ol1tbe2iRYvgyjDC0CAjMxQK5cyZM6WlpZ1mbBqmESUSyYgRI8hW/Zw5cyY8PBy2inYRGRmp0Wj27NkDW4gZgGZEw/BdRkYGLAEmefz48YABAwy7YFgFzs7Ozc3NxcXFsIW8LtD+4rm5uYYHFFJx8+bN0NBQ2CpejSVLlhjth2WNwDHijBkz6HR6yzZj5OHatWsQ+9I7jJeX19mzZ3fs2AFbSMeBYMR79+5t3LgxJCTE8qHbRiwW8/n8Hj16wBbSEUaPHt2zZ8+zZ8/CFtJBLL14SqvVYhhGpVItGbSd/Pzzz0qlcunSpbCF2CIWrRHz8vLmzJlDThcCAFJTUydNmgRbxeuyadOmixcvwlbxyljUiBkZGdu3b7dkxPZz48aNvn37enh4wBbyuiQmJubn51dUVMAW8mpY5bpmIpg2bdratWuDg4PbcS7C/FioRpRKpR9//LFlYnWA8+fPBwQEdCYX5uXlbd26FbaKV8BCRtyyZUv//v0tE6sD/PDDDytWrICtwpyEhYXR6fTTp0/DFtJeLHFr1ul0IpGIbEN5LWzevFkgEMyePRu2EJvGEjUijuOOjo4WCNQBSkpK7ty501ldWF1dnZWVBVtFu7CEEefPn5+fn2+BQB0gMTFx3bp1sFUQhYeHx+rVq0tLS2ELeTmEG1EsFjOZzIiICKIDdYCkpKTZs2f7+JhnM3Jysnnz5qqqKtgqXo7tdt9cvHjxzz///Oyzz2ALQQBL7Nfc1NREo9G4XHKlRi0rK9u6devx48dhC7EEJ06cUKlU06ZNgy2kLQi/Na9fv/7WrVtER3lV4uPjjxw5AluFhYiOjt67dy9sFS+BcCPyeDyyzbxftWrVvn376PROtVlGG7i4uKSkpJA8jY7NtRFXrlw5ZsyYYcOGwRaC+AuE14gVFRVarZboKO1kw4YNUVFRNujCsrKyhIQE2CragnAjfvLJJ0+ePCE6Sns4duyYm5vb9OnTYQuBgK+vr0wma2xshC2kVQg3Ynh4uE4Hf2eUw4cPFxcXv/vuu7CFQOPEiRMODg6wVbSKTbQRf//99/v3769evRq2EJgolUocx9lsku51RXiN2NTUBDchwdmzZ+/cuWPjLgQAXL9+fc2aNbBVtArhRrx79+4333xDdJTWOHbs2NWrVw053WwcPz+/mpoa2CpahfBbs1AonDx5skAgkEqlUqnUKE81oSQnJ/N4vNjYWItFRHQYoob4Fi1a9OjRo5aOG6VSach8mpmZaYH9AQxt88LCwq+//toCsayFhoYG0s7HI+rWvHPnzr/PamEymZZZNfzrr78WFRUhFxoxY8YMkUgEW4VpCGwjLlu2zNPTs+UtjuPh4eE0GuHTLJKTk+vr65cvX050IKvDyclJpVLBVmEaAo04ePDg8ePHczgcw1s7OzsLLFvZuHEjhUJJTEwkOpA1cvDgQW9vb9gqTEPsU/OiRYv69etnSK7l4ODQvXt3QsOtWbPGzc1t5syZhEaxXsgwstAahHffrFu3LigoSK/XCwSCoKAg4gJ9+umnkZGRJB9RhcvcuXNzcnJgqzBNu1psWo1eKdN3NAT28fLV69at69srRtpI1OyH1V+uHjNh+MiRIwkqv3MQERFB2gR2L+lHzLsteXRN3FCjZnFJmrDG8BjE4Ogbq/CACE7vYfYeASzYishF7969MQzDcbwlDyCO4yEhISkpKbClPaetGvH2uQZRlebNSe48RyuYQ4rjuLhOc/m32uhxTn5hJB1RhUJoaGh+fv6LaXC5XO7ChQuhijKm1Tbin2cbxHXaN+PcrMKFAAAMw+xdGeMX+vx5tqE0z+b2O26D6dOns1h/uUv4+fkNHz4cniITmDZio1Atqmx+Y7yrxfWYgeEJHvczyDvxzvLExsa+uHMMm82eO3cuVEUmMG1EUWUzjpMur3A7YTCpTXUaSYMGthASkZCQwGAwDK8DAwOHDh0KW5Expo0oE+tcfEi6DVh78AnlNAqREZ8TGxtr6MrmcDhz5syBLccEpo2oadZrVB3ur4GPrEmD6zr/hN9XIiEhgU6nBwYGknAzB0sssEd0gNLHcmmjViHRqZV6ldI8wyEc8MaQbv/s1q3bhUPm2cSPw6fpdTiHT+Pwqe4BdjyH13qoRUYkEfl3JQX35aW5cs8QvkaDU2lUKp0GKGbrteg3YBwAQGqmHgW5CtOqNfoyNa7HJakiFoca3JPTLZrPFXREMDIiKSi8L72WVu/gyaEyOd1GupBwB5q2ce0ClNLm8qeK3NtVAeHsgROdaPRXGz1GRoSMToef3lMjlwLvSA8Gy4p/DhaPyeIxnQMcGsrFO1c9HTLVJbw/v/2XW/E37wQIy1VHN1UE9ffk+5B0CLgDOPoIHH0EWbfq6iqbB09yaedVVrP7YedDXK8+s1fYbUSAHa/zuLAFt1CXehHlWlp9O89HRoRDTakq7cca/75e7TjXWnH0sRfWgP/90q6lg8iIENBq9KlbKv36dGYXGnDys1fIKXcvvHzEFRkRAqd/rg16o/O70IBTgFNpfnN5obzt05ARLU3OLbFcjjE51jGnySywnflXfntJYxEZ0dLcONngGkjSxcUEweIzKTRa4X1pG+eQyIirv/r4oxWLYasgluybYic/Ho1J0unuD7Mvrviiv1xu/lxFTgGOOX/I2jjBbEY8nnZk/bdfmau0zsrjuzImx4qnNXUYJpveUKNurG01fbLZjFhQkGeuojormmZ9XbmK62SjS2o4zuzirFYrRfOMrCQuX/TwYSYAID391M4dB7oEh2ZlPdi1Z2tBQR6GYWFdIxYu/GdY126Gk0+fSTtyNLmqqoLFYvfvF734vQ8dHZ2MCjx9Ju3YbwerqyuZTLvIHr2XLV3h6krSrfzaT0me3DmAR1z59x+du3LjYG3dUyaT3av7qDEjFjMYdgCA/SmfYRgI7TIg4+p+sbTO1dkvbvwKP5/uAACdTnvizPeZj87ien146MDgwD7EyeO5sGvKWm0mmqdGTFqzMaRL12FDR6WlXggMCC4vL13x8RIXZ9dtW/Zt3byXxWavWLlYKKwFAJw7d/q7/yaNGjnu592H13y1oaDw8arPPjBaSfjo0f3v/ps0edKMPbsPf7PuB7Gk6et/f2oWnXAR12l1GqJmM2TnXjlw9IuQ4H4fLU2eFvfFo5xLx35/lg2QSqU9LX1YVp6TuGT/V5+cZbMFh1OTDIcuXf3lz7tpE8Ykfrhkf4B/zwtXfiZIHgCAzqRVFytbO2oeI3K5XCqNRmcwBAJ7KpV64vdjLBZ71adrgoK6BAV1+XxVklarTT93CgBw9NiBmJjBCTPn+vj49ewZ9c9lKwsKH2dnP3yxtKclRUwmc/Rbb3t5eoeHRaz+Yv3SJR+ZRSdcZE1a4h5TLl3bH+jfe+zIJc5OPmEh0eNGLc18eLZJ/GzqoVqtnDAmkclgMRh2vXuMFopK1GoVAODew/9FhA/u1/ttZyef6H6TQ4IIzAlDt6Op5K3OrSTkqbmgMC+kS9eWfEtsNtvHx6+oqECr1RYVF4aHPU88EhoaDgB4UlTw4uW9evbBMOz9xAWnTh+vrqlydHQKDyPjVn6vikKmI8iIer2+oiovJLhfyyeB/r0BANU1z9LoOzv5GG7TAAA2iw8AUCglWq1GVF/u4xXecpWvdzci5LXA5FDlEtNLOAiZfaNQyJ0cnV/8hM3mKBRypcqQxpnz/HMWGwCgVP5lrqavr//WzXsPHf5l564t0o1rw8Iili1d0Qm8SFxKVI1Gpdfrzl3adT5jz4ufS6TPktDRaH+fV4Gr1UoAAP2FQ0wmsevBcR3e2lRLQozI4XDl8r88H8nlMidHZ5Ydi0KhKBTPR3vkCrnhfKMSgoK6/OuzJJ1Ol5X1YM/eHz/7PPFIypmWdWhWCldArasjJA0SnW5HpdIGvjGtf9SEv0TktNVzTmfYAQCUzc9/KaWyrT7n1wTHcbVKz+aZtpw5b80tzxyhIeH5BXkazbNKWCqTlpWVdO3ajUajBQeFZGU/aLkkN+dRyw26hby87JycRwAAKpXas2fUvLmLxeKmhob2TigiLVx7mlZNiBEpFIqXR9fGpmpXF3/DP0cHLwqFxma3NTWVTmM42HtU1xS2fFJQdJsIeQa0zTo7TqstE7MZkcflPXmSX/gkXyxuio2d2tys+va7NeXlpcXFT5LWfs7hcN8aNR4AMHXqrD/+uH7kaHJNTfX9B3e3bPsuMrJ3178a8c/bNz//YvmVqxcrqyoKn+Snpqa4u3m4ubmbSyos7F3oNCpRayOHDJyVlZtx6eovwrrSyqr8g8dWb9u9SKV6yVSDXt1HZede+eNuWnXNkys3DlRVF7R9/uugVmo9AlvtQzXbrTkubvo36798/4P5X3+1oV/fARv+s23n7i0LFs2gUqndI3p+/98d9vYOAIARw0c3N6uOHE3etXsrh8MdGDPkH//4wKioWQnztFrN9u2bRPV1HA43IiJy/TebrW4Zx9/x78Y5+0uNc6BzO859ZXp0Gzpj8tcZ1/anX9xpZ8f19+2xeN6Pdnactq8aOWyBXNF06uxmPa4PC4kZN2rZ/sOr9Dgh/1vkInmXHq1OATadDex2eoNaBSKHWOvY/KVDVZFvCvy7veRnsDzHt1XR+Dyesy3miCq6WT4l0UvgZHraEYkmPdgCXftxm2XNsFVAQCVTO3szW3MhWjxlacL68m+dKuG7cRks0z9Jdt7VlFTTmyFwWAK5Umzy0BtRE8eP/qe5RD4tfbAn2fQIgl6vo2AlNPAwAAAClklEQVQUYKqZNKDvpHGjlrZWpqi4YeDb9m0ERUa0NG9OdLpzsdGzm+lMayFB/ZYv+dXkIbVa1dIpbQSTac5GiLdnWGsaNJpmKpX+YqrF9miQN6rodNw/vC2RyIiWpksvXuEDuUrabHLxHoNh58jwNHWd5aDTmY4O5tSgapQOnfqSRzTURoTA2Lnuxber9HqbSBNVW1AX2ovl+rLkcsiIcJjxsW/xHxWwVRBObWG9iwclIlrw0jOREeHg4MqY+YlX4fUyndaK0/+1TV1RfVA4fVh8u/IOIyNCg82lT/vIu/B6mbyx1Vl6Vopeq6/MrvEPofUZ4dDOS5ARYcJ3pL/3nyC6Xl7xsFop6ST9i3VPG/Ovlg0cZ9931CsMiKCnZviMmuVWXqC4elzE5DIpDAbfhUPaZX5tIKtXykQKiVAWOch+6pJX3mIMGZEU+ISwEz7xLc2VFzyQF9+udPBgqVV6GoNGZdAwCkkH2SlUikap1ml0ANc3VitdfezCozjhb/i/amZEA8iIJMIvnOMXzgEA1JappI1ahUSrUuibFSTdyZHFxTEKjcNnsvk0jwB3OuO1mnnIiGTEzdfOzRe2CMti2ogMO0wPSHpHaA8cezqFasX6bRDT1SnPgV5XasV9CmV5Mkd3615XYGuYNqKrD9N656EqZVpnLybXHrU6rIlWa0SvYLurv7Ur1yfZuJBc1Xdke/tRESShrf2ac26JCx/IIgc7ObgxqDSyd32rFDqJSH3jhHD0u26uvraY6MiqecnG4U9z5A+uNNU8VVFppL5VC5zpkgaNfzinz0gHB1fUOrQ+XmLEFpqVpB6bx/XAjkP2OhvRBu01IgJBKKgWQZACZEQEKUBGRJACZEQEKUBGRJACZEQEKfg/zsZU4/1PoqEAAAAASUVORK5CYII=\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}}],"source":["#5\n","\n","class GraphState(TypedDict):\n","    messages: Annotated[list[AnyMessage], operator.add]\n","\n","def create_langgraph(tools):\n","\n","    def should_continue(state: GraphState):\n","        messages = state[\"messages\"]\n","        last_message = messages[-1]\n","        if last_message.tool_calls:\n","            return \"tools\"\n","        return END\n","\n","    def call_llm(state: GraphState):\n","        response = chain.invoke({\"messages\":state[\"messages\"]})\n","        print(\"====response====\")\n","        print(response)\n","        return {\"messages\": [response]}\n","\n","    tool_node = ToolNode(tools)\n","\n","    workflow = StateGraph(GraphState)\n","    workflow.add_node(\"agent\", call_llm)\n","    workflow.add_node(\"tools\", tool_node)\n","\n","    workflow.add_edge(START, \"agent\")\n","    workflow.add_conditional_edges(\"agent\", should_continue, [\"tools\", END])\n","    workflow.add_edge(\"tools\", \"agent\")\n","\n","    memory = MemorySaver()\n","    graph = workflow.compile(checkpointer=memory)\n","    return graph\n","\n","graph = create_langgraph(tools)\n","\n","from IPython.display import Image, display\n","display(Image(graph.get_graph().draw_mermaid_png()))"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fELgChOVjzzn","executionInfo":{"status":"ok","timestamp":1746967405731,"user_tz":-540,"elapsed":130563,"user":{"displayName":"하호진","userId":"01408081046197671833"}},"outputId":"b425deef-7223-4bdf-feb7-4ef32fda1bb6"},"outputs":[{"output_type":"stream","name":"stdout","text":["질문을 입력해주세요: 최신 동영상 생성 AI(오픈 모델) 중에 애니메이션풍의 동영상을 품질 높게 생성할 수 있는 모델을 조사해 주세요. 출력 시에는 정밀도에 대해 조사한 후 현시점에서 가장 고성능인 모델을 알려주세요. 또한 그 모델의 이용 방법 등에 대해서도 알고 싶습니다. 또 상용 이용이 가능한 라이선스로 좁혀주세요.\n","################# 질문 #################\n","질문: 최신 동영상 생성 AI(오픈 모델) 중에 애니메이션풍의 동영상을 품질 높게 생성할 수 있는 모델을 조사해 주세요. 출력 시에는 정밀도에 대해 조사한 후 현시점에서 가장 고성능인 모델을 알려주세요. 또한 그 모델의 이용 방법 등에 대해서도 알고 싶습니다. 또 상용 이용이 가능한 라이선스로 좁혀주세요.\n","====response====\n","content=\"네, 최신 오픈 소스 동영상 생성 AI 모델 중 애니메이션풍의 고품질 동영상을 생성할 수 있고 상용 이용이 가능한 모델에 대해 조사해 보겠습니다.\\n\\n이 분야는 매우 빠르게 발전하고 있으며, '최고 성능'은 기준이나 사용 방법에 따라 달라질 수 있습니다. 현재 시점에서 애니메이션 스타일에 특히 강점을 보이거나 해당 스타일 구현에 널리 사용되는 오픈 소스 기술을 중심으로 찾아보겠습니다.\\n\\n`tavily_search_tool`을 사용하여 관련 정보를 검색하겠습니다.\" additional_kwargs={'function_call': {'name': 'tavily_search', 'arguments': '{\"search_depth\": \"advanced\", \"time_range\": \"year\", \"query\": \"latest open source video generation AI anime high quality commercial use\"}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'models/gemini-2.5-flash-preview-04-17', 'safety_ratings': []} id='run-098c0b76-5f20-4bde-9319-62c0166ae187-0' tool_calls=[{'name': 'tavily_search', 'args': {'search_depth': 'advanced', 'time_range': 'year', 'query': 'latest open source video generation AI anime high quality commercial use'}, 'id': '404458b1-e5ba-4c21-a460-036efed071b2', 'type': 'tool_call'}] usage_metadata={'input_tokens': 1145, 'output_tokens': 155, 'total_tokens': 4422, 'input_token_details': {'cache_read': 0}}\n","====response====\n","content='생각하는 과정:\\n\\n1.  **사용자 요청 분석:** 사용자는 최신 오픈 소스 동영상 생성 AI 모델 중 애니메이션 스타일의 고품질 동영상을 상업적으로 이용 가능한 라이선스로 생성할 수 있는 모델을 찾고 있습니다. 모델의 정밀도(품질, 프롬프트 준수 등)와 이용 방법도 알고 싶어 합니다.\\n\\n2.  **필요한 정보 식별:**\\n    *   최신 오픈 소스 동영상 생성 AI 모델 목록.\\n    *   각 모델의 애니메이션 스타일 생성 능력 및 품질.\\n    *   각 모델의 라이선스 (상업적 이용 가능 여부).\\n    *   각 모델의 정밀도 (품질, 프롬프트 준수, 해상도, 프레임 속도 등).\\n    *   가장 고성능인 모델 식별 (위 기준 종합).\\n    *   선택된 모델의 이용 방법.\\n\\n3.  **검색 전략 수립:** 사용자의 요청에 맞춰 키워드를 조합하여 검색합니다.\\n    *   키워드: \"latest open source video generation AI anime high quality commercial use\"\\n    *   검색 깊이: 상세한 정보를 위해 \"advanced\"\\n    *   시간 범위: \"최신\" 정보를 위해 \"year\"\\n\\n4.  **검색 실행:** `tavily_search` 툴을 사용하여 검색을 수행합니다.\\n    *   `print(default_api.tavily_search(query = \"latest open source video generation AI anime high quality commercial use\", search_depth = \"advanced\", time_range = \"year\"))`\\n\\n5.  **검색 결과 분석:** 검색 결과를 검토하여 각 모델에 대한 정보를 추출합니다.\\n    *   **Hunyuan Video (Tencent):** 오픈 소스, 13B 파라미터, 고품질 시네마틱 (실사/가상 스타일), 720p 해상도, 텍스트-비디오 정렬 및 모션 다양성 우수. 강력한 오픈 소스 중 하나로 언급됨. 상업적 이용 라이선스는 명확히 언급되지 않음.\\n    *   **Mochi-1 (Genmo AI):** 오픈 소스, 10B 파라미터, 30fps 부드러운 모션, 강력한 프롬프트 준수. Apache 2.0 라이선스 (상업적 이용 가능). 연구, 제품 개발, 창의적 표현 등에 적합하다고 언급됨.\\n    *   **Hailuo AI:** 카툰 스타일 템플릿, Director Mode. 플랫폼 형태. 오픈 소스 모델 자체인지는 불분명. 상업적 이용 가능성 언급 (무료/유료).\\n    *   **PixVerse AI, Vidu AI:** 상업적 이용 가능성 언급. 플랫폼 형태일 가능성 높음. 오픈 소스 모델인지는 불분명.\\n    *   **Sora, Runway Gen-2, Pika Labs, Stable Video Diffusion:** 언급은 되지만, 오픈 소스 여부, 애니메이션 특화, 상업적 이용 라이선스가 명확히 연결되어 설명되지 않음.\\n    *   **GPT-4o, DALL-E 3:** 이미지 생성 모델. 동영상 생성 요청과는 다름.\\n\\n6.  **최적 모델 선정:** 사용자의 요구사항 (오픈 소스, 애니메이션 스타일, 고품질, 상업적 이용 가능 라이선스, 정밀도)을 모두 만족하는 모델을 찾습니다.\\n    *   Hunyuan과 Mochi-1이 주요 오픈 소스 후보입니다.\\n    *   Hunyuan은 강력하고 고품질이지만, 상업적 이용 라이선스가 검색 결과에서 명확히 확인되지 않았습니다.\\n    *   Mochi-1은 오픈 소스이며, Apache 2.0 라이선스로 상업적 이용이 명시적으로 가능합니다. 30fps 모션과 강력한 프롬프트 준수는 정밀도 측면에서 긍정적입니다. 애니메이션 스타일에 특화되었다는 명시는 없지만, \"창의적 표현\"에 적합하다는 설명과 텍스트 프롬프트 기반이라는 점에서 다양한 스타일 시도가 가능할 것으로 보입니다.\\n    *   따라서 상업적 이용 가능 라이선스가 명확한 Mochi-1이 현재 검색 결과만으로는 가장 적합한 모델로 판단됩니다.\\n\\n7.  **선택된 모델 정보 정리:** Mochi-1에 대한 정보를 종합합니다.\\n    *   모델명: Mochi-1 (Genmo AI 개발)\\n    *   특징: 오픈 소스, 100억(10B) 파라미터, 30fps 부드러운 모션, 강력한 프롬프트 준수.\\n    *   라이선스: Apache 2.0 (상업적 이용 가능).\\n    *   정밀도: 30fps 모션, 강력한 프롬프트 준수, 고품질 동영상 생성 가능.\\n    *   이용 방법: 텍스트 프롬프트 기반으로 동영상 생성. 공식 웹사이트(mochi1ai.com) 또는 관련 GitHub/문서 참고 필요. 로컬 설치 가능성도 언급됨.\\n\\n8.  **응답 구성:** 사용자에게 조사 결과를 바탕으로 답변을 작성합니다.\\n    *   조사 결과, 현재 시점에서 사용자의 요구사항(오픈 소스, 고품질, 상업적 이용 가능)에 가장 부합하는 모델은 Mochi-1임을 알립니다.\\n    *   Mochi-1의 특징과 장점(오픈 소스, Apache 2.0 라이선스, 30fps, 프롬프트 준수)을 설명합니다.\\n    *   정밀도 측면에서 Mochi-1의 강점을 언급합니다.\\n    *   이용 방법은 텍스트 프롬프트 기반이며, 자세한 내용은 공식 웹사이트나 관련 문서를 참고해야 함을 안내합니다.\\n    *   Hunyuan Video도 강력한 오픈 소스 모델이지만, 상업적 이용 라이선스 정보가 Mochi-1만큼 명확하지 않음을 덧붙여 비교 정보를 제공합니다.\\n    *   애니메이션 스타일에 특화된 모델은 아니지만, 텍스트 프롬프트와 창의적 표현 기능을 통해 애니메이션 스타일 구현이 가능할 수 있음을 시사합니다.\\n\\n9.  **한국어 번역 및 다듬기:** 작성된 내용을 자연스러운 한국어로 번역하고 사용자 친화적으로 다듬습니다.최신 오픈 소스 동영상 생성 AI 모델 중 애니메이션풍의 고품질 동영상을 상업적으로 이용 가능한 라이선스로 생성할 수 있는 모델을 조사한 결과, 현재 시점에서 가장 주목할 만한 모델은 **Mochi-1**입니다.\\n\\n**Mochi-1 (Genmo AI 개발)**\\n\\n*   **특징:** Mochi-1은 100억(10B) 개의 파라미터를 가진 오픈 소스 텍스트-투-비디오 모델입니다. 특히 30 프레임/초(fps)의 부드러운 모션과 텍스트 프롬프트에 대한 강력한 준수 능력이 강점입니다.\\n*   **정밀도:** 고품질 동영상 생성을 목표로 하며, 특히 모션의 자연스러움과 사용자의 입력(프롬프트)을 정확하게 반영하는 데 중점을 둡니다. 애니메이션 스타일에 특화되었다고 명시되어 있지는 않지만, 강력한 프롬프트 준수와 창의적 표현 기능을 통해 다양한 스타일의 동영상 생성이 가능할 것으로 보입니다.\\n*   **라이선스:** Mochi-1은 Apache 2.0 라이선스로 제공됩니다. 이 라이선스는 상업적 이용을 포함하여 매우 자유로운 사용을 허용합니다. 따라서 상업적 목적으로 생성된 동영상을 활용하는 데 문제가 없습니다.\\n*   **이용 방법:** 기본적으로 텍스트 프롬프트를 입력하여 원하는 동영상을 생성하는 방식입니다. 모델 자체를 다운로드하여 로컬 환경에 설치하거나, Genmo AI 등 관련 플랫폼을 통해 접근할 수 있습니다. 자세한 이용 방법이나 설치 가이드는 Mochi-1의 공식 웹사이트(mochi1ai.com)나 관련 GitHub 저장소를 참고하시는 것이 가장 정확합니다.\\n\\n**다른 모델과의 비교:**\\n\\nHunyuan Video (Tencent 개발) 역시 130억(13B) 파라미터의 강력한 오픈 소스 모델로 언급되며, 고품질 시네마틱 동영상 생성에 뛰어나고 720p 해상도를 지원합니다. 하지만 검색 결과만으로는 Hunyuan Video의 상업적 이용 라이선스가 Mochi-1의 Apache 2.0처럼 명확하게 확인되지는 않았습니다. 사용자의 요구사항 중 \\'상업적 이용 가능한 라이선스\\'가 중요한 기준이므로, 이 점에서는 Mochi-1이 더 확실한 선택일 수 있습니다.\\n\\n결론적으로, 오픈 소스이며 상업적 이용이 명확히 허용되는 라이선스를 가진 고품질 동영상 생성 모델로는 현재 Mochi-1이 가장 적합한 것으로 판단됩니다. 이용을 원하시면 Mochi-1의 공식 채널을 통해 상세한 사용법과 기술 문서를 확인하시기 바랍니다.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'models/gemini-2.5-flash-preview-04-17', 'safety_ratings': []} id='run-f63f1ba7-24bc-4e3e-88e1-153f0d2af536-0' usage_metadata={'input_tokens': 3957, 'output_tokens': 2033, 'total_tokens': 7105, 'input_token_details': {'cache_read': 0}}\n","response:  {'messages': [HumanMessage(content=[{'type': 'text', 'text': '최신 동영상 생성 AI(오픈 모델) 중에 애니메이션풍의 동영상을 품질 높게 생성할 수 있는 모델을 조사해 주세요. 출력 시에는 정밀도에 대해 조사한 후 현시점에서 가장 고성능인 모델을 알려주세요. 또한 그 모델의 이용 방법 등에 대해서도 알고 싶습니다. 또 상용 이용이 가능한 라이선스로 좁혀주세요.'}], additional_kwargs={}, response_metadata={}), AIMessage(content=\"네, 최신 오픈 소스 동영상 생성 AI 모델 중 애니메이션풍의 고품질 동영상을 생성할 수 있고 상용 이용이 가능한 모델에 대해 조사해 보겠습니다.\\n\\n이 분야는 매우 빠르게 발전하고 있으며, '최고 성능'은 기준이나 사용 방법에 따라 달라질 수 있습니다. 현재 시점에서 애니메이션 스타일에 특히 강점을 보이거나 해당 스타일 구현에 널리 사용되는 오픈 소스 기술을 중심으로 찾아보겠습니다.\\n\\n`tavily_search_tool`을 사용하여 관련 정보를 검색하겠습니다.\", additional_kwargs={'function_call': {'name': 'tavily_search', 'arguments': '{\"search_depth\": \"advanced\", \"time_range\": \"year\", \"query\": \"latest open source video generation AI anime high quality commercial use\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'models/gemini-2.5-flash-preview-04-17', 'safety_ratings': []}, id='run-098c0b76-5f20-4bde-9319-62c0166ae187-0', tool_calls=[{'name': 'tavily_search', 'args': {'search_depth': 'advanced', 'time_range': 'year', 'query': 'latest open source video generation AI anime high quality commercial use'}, 'id': '404458b1-e5ba-4c21-a460-036efed071b2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1145, 'output_tokens': 155, 'total_tokens': 4422, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='{\"query\": \"latest open source video generation AI anime high quality commercial use\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://deevid.ai/blog/luma-ai-alternatives-for-text-to-video-ai-easy-to-use-free-trial\", \"title\": \"Best 10 Luma AI Alternatives for Text to Video AI(Easy to Use & Free ...\", \"content\": \"Hailuo AI | Cartoon-style storytelling templates | Web, iOS, Android | Free (with premium options)Premium $9.99+\\\\nVidu AI | Photorealistic video from prompts | Commercial use | Free (with premium options)Premium $8+\\\\nPixVerse AI | Video generation via prompts & anime effects | Web, iOS, Android | Free (with premium options)Premium $10+\\\\nVeo 2 | Latest high-quality generative video model | Web | Free (with premium options)Premium $29.9+ [...] Hunyuan AI Video is an advanced AI video creation tool that turns text descriptions into high-definition, visually stunning videos. It boasts a robust 13B-parameter model and is among the strongest open-source video generation software on the market today. Hunyuan has impressive rendering capacity, with a maximum resolution of 720p x 1280p for sharp, cinematic output. With its huge amount of creative power and accuracy, it\\'s excellent for producing professional content ranging from brand [...] Hailuo Video transforms your ideas into high-quality, stunning videos in a few clicks. It generates professional content based on the latest AI technology from simple text or image inputs—without needing any editing skills. The Hailuo AI Video Generator merges powerful features and smart customization to allow you to create excellent visuals with little effort. Whether you are creating animated avatars, promotional videos, or stylish edits, Hailuo Video makes professional video production\", \"score\": 0.7728226, \"raw_content\": null}, {\"url\": \"https://www.toolify.ai/ai-news/top-open-source-ai-video-generation-models-ranked-3341463\", \"title\": \"Top Open Source AI Video Generation Models Ranked - Toolify.ai\", \"content\": \"Number 2: Hunyuan Video - High Quality Virtual Creation\\\\n\\\\nHunyuan Video\\\\n\\\\n, developed by Tencent, is a powerful open-source video generation model with 13 billion parameters. It\\'s designed for high-quality, cinematic video generation and supports both real and virtual styles. Hunyuan Video uses a hybrid architecture, combining 3D VAE for video compression and multimodal language models for text encoding. [...] The model employs a dual-stream single-stream design to integrate visual and semantic information effectively. It also features a Prompt rewrite module to enhance user input comprehension, ensuring high-quality outputs. Hunyuan Video excels in text-video alignment, motion diversity, and visual quality. It supports 720p resolution and can generate long, continuous sequences with rich semantic expressions. [...] , developed by Genmo AI, is an open-source text-to-video model that emphasizes creative freedom and high-quality outputs. It\\'s particularly known for its smooth motion and adherence to textual prompts. Mochi-1 leverages a diffusion-based framework combined with the AsymDIT architecture. This design allows the model to process Spatial and temporal information effectively, ensuring smooth transitions and realistic motion.\", \"score\": 0.7467494, \"raw_content\": null}, {\"url\": \"https://www.tomsguide.com/features/5-best-ai-video-generators-tested-and-compared\", \"title\": \"I\\'ve spent 200 hours testing the best AI video generators - Tom\\'s Guide\", \"content\": \"The latest version, Pika 2.1, launched on February 3, 2025, introduces high-definition 1080p video generation, enabling users to create more detailed and visually appealing content.\\\\n\\\\nThe new Pikadditions feature allows users to seamlessly integrate any person or object into existing videos, expanding creative possibilities. [...] The journey began in February 2023 when Runway introduced Gen-2, the first commercially available AI video generator, transitioning from its initial Discord-based testing phase. This milestone was quickly followed by Pika Labs launching Pika 1.0, and the emergence of several services based on Stable Video Diffusion. A significant breakthrough occurred earlier this year with OpenAI\\'s unveiling of Sora, demonstrating that extensive computational resources and vast training datasets are crucial [...] Director mode for enhanced control: Hailuo AI has introduced a \\'Director Mode,\\' granting users greater control over video generation. This mode allows for detailed customization of scenes, movements, and character interactions, ensuring the final output aligns closely with the user\\'s vision.\\\\n\\\\nThe free plan includes daily credits every time you log in and the base subscription is $9.99 per month for 1000 credits, bonus credits for daily login and no watermarks.\\\\n\\\\nBest for Storyboarding\\\\n\\\\n\\\\n\\\\nSora\", \"score\": 0.69870013, \"raw_content\": null}, {\"url\": \"https://mochi1ai.com/\", \"title\": \"Mochi 1: AI Video Generator\", \"content\": \"Mochi 1: Revolutionary AI Video Generation\\\\n\\\\nCreate stunning videos with state-of-the-art AI technology.\\\\n\\\\nMochi 1 Video Gallery\\\\n\\\\nBe inspired by the incredible videos created using Mochi 1\\\\n\\\\nMeet Mochi 1: The Future of AI Video Generation\\\\n\\\\nMochi 1 is a groundbreaking open-source AI model that\\'s changing the game in video generation. It\\'s not just another AI tool - it\\'s a powerhouse that creates stunning, high-quality videos from simple text prompts. [...] Explore the cutting-edge features that set Mochi 1 apart\\\\n\\\\nHigh-Fidelity Motion\\\\n\\\\nMochi 1 generates smooth, realistic motion at 30 frames per second.\\\\n\\\\nStrong Prompt Adherence\\\\n\\\\nExceptional alignment with textual prompts for precise video creation.\\\\n\\\\nOpen-Source Power\\\\n\\\\nBenefit from a 10 billion parameter model, freely available under Apache 2.0 license.\\\\n\\\\nVersatile Applications\\\\n\\\\nPerfect for research, product development, creative expression, and more.\\\\n\\\\nFrequently Asked Questions\\\\n\\\\nWhat is Mochi 1? [...] With its massive 10 billion parameter architecture, Mochi 1 delivers smooth, realistic motion at 30 frames per second. It\\'s like having a professional video production team at your fingertips, ready to bring your ideas to life in seconds.\", \"score\": 0.6755297, \"raw_content\": null}, {\"url\": \"https://monica.im/blog/best-ai-anime-generators/\", \"title\": \"Best Anime AI Generator of 2025: Models & Tools Compared - Monica\", \"content\": \"According to PCGamer\\'s March 2025 review, GPT-4o\\'s anime generation capabilities have \\\\\"flooded social media\\\\\" with high-quality anime-style transformations. The model\\'s strength lies in its ability to understand and implement stylistic nuances through natural language conversation, allowing users to refine their images through dialogue rather than technical parameters.\\\\n\\\\nTop Anime AI Generator Tools in 2025 [...] While not specifically optimized for anime like some competitors, DALL·E 3 produces high-quality anime-style images with particularly strong scene composition and character consistency.\\\\n\\\\n5. GPT-4o Image Generation: The 2025 Breakthrough\\\\n\\\\n💰 Price: Available through ChatGPT Plus ($20/month) and API access\\\\n\\\\n✨ Key Features:\\\\n\\\\n👍 GPT-4o Image Generation Model Best For: Users seeking high-quality anime generation with natural language interaction and emotional depth. [...] In 2025, the landscape of AI anime generation models has evolved significantly. These models have become more sophisticated, offering unprecedented capabilities in creating high-quality anime art. As technology advances, several standout models have emerged, each with unique features and strengths. This introduction explores the top AI anime generation models of 2025, highlighting their innovative contributions to the world of anime creation.\\\\n\\\\nAnime AI Generator Models Comparison\", \"score\": 0.6461259, \"raw_content\": null}, {\"url\": \"https://www.goenhance.ai/tools/hunyuan-video\", \"title\": \"Hunyuan Video - Open Source AI Video Generation - GoEnhance AI\", \"content\": \"Enter Your Prompt\\\\n\\\\nBegin by providing a detailed text prompt or uploading an image to inspire your video.\\\\n\\\\nPersonalize Your Video\\\\n\\\\nChoose your preferred video mode, style, and creative options to bring your vision to life.\\\\n\\\\nCreate and Download\\\\n\\\\nLet the AI generate your video, preview the results, and download your high-quality creation.\\\\n\\\\nFrequently Asked Questions\\\\n\\\\nWhat is Hunyuan AI Video Generator?\\\\n\\\\nWhat makes Hunyuan Video unique compared to other video generation models? [...] Hunyuan Video\\\\n\\\\nHunyuan Video Generator Features\\\\n\\\\nSeamless Multi-Action Generation\\\\n\\\\nEffortlessly generate complex, continuous actions with rich semantic understanding and smooth transitions.\\\\n\\\\nCinematic Camera Movements\\\\n\\\\nBreak free from static shots with intelligent, director-level camera work and seamless scene transitions.\\\\n\\\\nPhysics-Based Realism\\\\n\\\\nEnsure every frame follows real-world physics for immersive, natural, and convincing video results.\\\\n\\\\nHow To Use Hunyuan AI Video Generator? [...] Is it free to use Hunyuan video AI?\\\\n\\\\nWhat video resolutions and aspect ratios does HunyuanVideo support?\\\\n\\\\nWhat are the prompt rewrite modes available in HunyuanVideo?\\\\n\\\\nWhat Our Users Say？\\\\n\\\\nTry Hunyuan AI\\\\n\\\\nExplore the powerful Hunyuan AI video generator\\\\n\\\\nVideo Tools\\\\n\\\\nImage Tools\\\\n\\\\nVideo Models\\\\n\\\\nResource\", \"score\": 0.62495816, \"raw_content\": null}, {\"url\": \"https://www.youtube.com/watch?v=he8nLSvY-yU&pp=0gcJCdgAo7VqN5tD\", \"title\": \"The BEST open-source AI video generator is here (beats Runway ...\", \"content\": \"Sources:\\\\nhttps://www.genmo.ai/play\\\\nhttps://github.com/kijai/ComfyUI-MochiWrapper\\\\nhttps://rhymes.ai/allegro_gallery\\\\nhttps://github.com/rhymes-ai/Aria\\\\n\\\\n0:00 Genmo Mochi 1 \\\\n2:45 Rhymes AI Allegro\\\\n4:06 Comparison w Kling and Minimax\\\\n31:27 Local installation\\\\n\\\\nNewsletter: https://aisearch.substack.com/\\\\nFind AI tools & jobs: https://ai-search.io/\\\\nSupport: https://ko-fi.com/aisearch [...] The BEST open-source AI video generator is here (beats Runway Gen3) \\\\n AI Search \\\\n 3865 likes \\\\n 153032 views \\\\n 30 Oct 2024 \\\\n Genmo Mochi 1 and Rhymes Allegro full testing & review. Free open source AI video generators have caught up! #ainews #ai #aivideo \\\\n\\\\nThanks to our sponsor Abacus AI. Try their new ChatLLM platform here: http://chatllm.abacus.ai/?token=aisearch [...] Here\\'s my equipment, in case you\\'re wondering:\\\\nDell Precision 5690: https://www.dell.com/en-us/dt/ai-technologies/index.htm?utm_source=AISearchTools&utm_medium=youtube&utm_campaign=precisionai#tab0=0 \\\\nGPU: Nvidia RTX 5000 Ada https://nvda.ws/3zfqGqS\\\\nMouse/Keyboard: ALOGIC Echelon https://bit.ly/alogic-echelon\\\\nMic: Shure SM7B https://amzn.to/3DErjt1\\\\nAudio interface: Scarlett Solo https://amzn.to/3qELMeu \\\\n 289 comments\", \"score\": 0.46191534, \"raw_content\": null}], \"response_time\": 2.97}', name='tavily_search', tool_call_id='404458b1-e5ba-4c21-a460-036efed071b2'), AIMessage(content='생각하는 과정:\\n\\n1.  **사용자 요청 분석:** 사용자는 최신 오픈 소스 동영상 생성 AI 모델 중 애니메이션 스타일의 고품질 동영상을 상업적으로 이용 가능한 라이선스로 생성할 수 있는 모델을 찾고 있습니다. 모델의 정밀도(품질, 프롬프트 준수 등)와 이용 방법도 알고 싶어 합니다.\\n\\n2.  **필요한 정보 식별:**\\n    *   최신 오픈 소스 동영상 생성 AI 모델 목록.\\n    *   각 모델의 애니메이션 스타일 생성 능력 및 품질.\\n    *   각 모델의 라이선스 (상업적 이용 가능 여부).\\n    *   각 모델의 정밀도 (품질, 프롬프트 준수, 해상도, 프레임 속도 등).\\n    *   가장 고성능인 모델 식별 (위 기준 종합).\\n    *   선택된 모델의 이용 방법.\\n\\n3.  **검색 전략 수립:** 사용자의 요청에 맞춰 키워드를 조합하여 검색합니다.\\n    *   키워드: \"latest open source video generation AI anime high quality commercial use\"\\n    *   검색 깊이: 상세한 정보를 위해 \"advanced\"\\n    *   시간 범위: \"최신\" 정보를 위해 \"year\"\\n\\n4.  **검색 실행:** `tavily_search` 툴을 사용하여 검색을 수행합니다.\\n    *   `print(default_api.tavily_search(query = \"latest open source video generation AI anime high quality commercial use\", search_depth = \"advanced\", time_range = \"year\"))`\\n\\n5.  **검색 결과 분석:** 검색 결과를 검토하여 각 모델에 대한 정보를 추출합니다.\\n    *   **Hunyuan Video (Tencent):** 오픈 소스, 13B 파라미터, 고품질 시네마틱 (실사/가상 스타일), 720p 해상도, 텍스트-비디오 정렬 및 모션 다양성 우수. 강력한 오픈 소스 중 하나로 언급됨. 상업적 이용 라이선스는 명확히 언급되지 않음.\\n    *   **Mochi-1 (Genmo AI):** 오픈 소스, 10B 파라미터, 30fps 부드러운 모션, 강력한 프롬프트 준수. Apache 2.0 라이선스 (상업적 이용 가능). 연구, 제품 개발, 창의적 표현 등에 적합하다고 언급됨.\\n    *   **Hailuo AI:** 카툰 스타일 템플릿, Director Mode. 플랫폼 형태. 오픈 소스 모델 자체인지는 불분명. 상업적 이용 가능성 언급 (무료/유료).\\n    *   **PixVerse AI, Vidu AI:** 상업적 이용 가능성 언급. 플랫폼 형태일 가능성 높음. 오픈 소스 모델인지는 불분명.\\n    *   **Sora, Runway Gen-2, Pika Labs, Stable Video Diffusion:** 언급은 되지만, 오픈 소스 여부, 애니메이션 특화, 상업적 이용 라이선스가 명확히 연결되어 설명되지 않음.\\n    *   **GPT-4o, DALL-E 3:** 이미지 생성 모델. 동영상 생성 요청과는 다름.\\n\\n6.  **최적 모델 선정:** 사용자의 요구사항 (오픈 소스, 애니메이션 스타일, 고품질, 상업적 이용 가능 라이선스, 정밀도)을 모두 만족하는 모델을 찾습니다.\\n    *   Hunyuan과 Mochi-1이 주요 오픈 소스 후보입니다.\\n    *   Hunyuan은 강력하고 고품질이지만, 상업적 이용 라이선스가 검색 결과에서 명확히 확인되지 않았습니다.\\n    *   Mochi-1은 오픈 소스이며, Apache 2.0 라이선스로 상업적 이용이 명시적으로 가능합니다. 30fps 모션과 강력한 프롬프트 준수는 정밀도 측면에서 긍정적입니다. 애니메이션 스타일에 특화되었다는 명시는 없지만, \"창의적 표현\"에 적합하다는 설명과 텍스트 프롬프트 기반이라는 점에서 다양한 스타일 시도가 가능할 것으로 보입니다.\\n    *   따라서 상업적 이용 가능 라이선스가 명확한 Mochi-1이 현재 검색 결과만으로는 가장 적합한 모델로 판단됩니다.\\n\\n7.  **선택된 모델 정보 정리:** Mochi-1에 대한 정보를 종합합니다.\\n    *   모델명: Mochi-1 (Genmo AI 개발)\\n    *   특징: 오픈 소스, 100억(10B) 파라미터, 30fps 부드러운 모션, 강력한 프롬프트 준수.\\n    *   라이선스: Apache 2.0 (상업적 이용 가능).\\n    *   정밀도: 30fps 모션, 강력한 프롬프트 준수, 고품질 동영상 생성 가능.\\n    *   이용 방법: 텍스트 프롬프트 기반으로 동영상 생성. 공식 웹사이트(mochi1ai.com) 또는 관련 GitHub/문서 참고 필요. 로컬 설치 가능성도 언급됨.\\n\\n8.  **응답 구성:** 사용자에게 조사 결과를 바탕으로 답변을 작성합니다.\\n    *   조사 결과, 현재 시점에서 사용자의 요구사항(오픈 소스, 고품질, 상업적 이용 가능)에 가장 부합하는 모델은 Mochi-1임을 알립니다.\\n    *   Mochi-1의 특징과 장점(오픈 소스, Apache 2.0 라이선스, 30fps, 프롬프트 준수)을 설명합니다.\\n    *   정밀도 측면에서 Mochi-1의 강점을 언급합니다.\\n    *   이용 방법은 텍스트 프롬프트 기반이며, 자세한 내용은 공식 웹사이트나 관련 문서를 참고해야 함을 안내합니다.\\n    *   Hunyuan Video도 강력한 오픈 소스 모델이지만, 상업적 이용 라이선스 정보가 Mochi-1만큼 명확하지 않음을 덧붙여 비교 정보를 제공합니다.\\n    *   애니메이션 스타일에 특화된 모델은 아니지만, 텍스트 프롬프트와 창의적 표현 기능을 통해 애니메이션 스타일 구현이 가능할 수 있음을 시사합니다.\\n\\n9.  **한국어 번역 및 다듬기:** 작성된 내용을 자연스러운 한국어로 번역하고 사용자 친화적으로 다듬습니다.최신 오픈 소스 동영상 생성 AI 모델 중 애니메이션풍의 고품질 동영상을 상업적으로 이용 가능한 라이선스로 생성할 수 있는 모델을 조사한 결과, 현재 시점에서 가장 주목할 만한 모델은 **Mochi-1**입니다.\\n\\n**Mochi-1 (Genmo AI 개발)**\\n\\n*   **특징:** Mochi-1은 100억(10B) 개의 파라미터를 가진 오픈 소스 텍스트-투-비디오 모델입니다. 특히 30 프레임/초(fps)의 부드러운 모션과 텍스트 프롬프트에 대한 강력한 준수 능력이 강점입니다.\\n*   **정밀도:** 고품질 동영상 생성을 목표로 하며, 특히 모션의 자연스러움과 사용자의 입력(프롬프트)을 정확하게 반영하는 데 중점을 둡니다. 애니메이션 스타일에 특화되었다고 명시되어 있지는 않지만, 강력한 프롬프트 준수와 창의적 표현 기능을 통해 다양한 스타일의 동영상 생성이 가능할 것으로 보입니다.\\n*   **라이선스:** Mochi-1은 Apache 2.0 라이선스로 제공됩니다. 이 라이선스는 상업적 이용을 포함하여 매우 자유로운 사용을 허용합니다. 따라서 상업적 목적으로 생성된 동영상을 활용하는 데 문제가 없습니다.\\n*   **이용 방법:** 기본적으로 텍스트 프롬프트를 입력하여 원하는 동영상을 생성하는 방식입니다. 모델 자체를 다운로드하여 로컬 환경에 설치하거나, Genmo AI 등 관련 플랫폼을 통해 접근할 수 있습니다. 자세한 이용 방법이나 설치 가이드는 Mochi-1의 공식 웹사이트(mochi1ai.com)나 관련 GitHub 저장소를 참고하시는 것이 가장 정확합니다.\\n\\n**다른 모델과의 비교:**\\n\\nHunyuan Video (Tencent 개발) 역시 130억(13B) 파라미터의 강력한 오픈 소스 모델로 언급되며, 고품질 시네마틱 동영상 생성에 뛰어나고 720p 해상도를 지원합니다. 하지만 검색 결과만으로는 Hunyuan Video의 상업적 이용 라이선스가 Mochi-1의 Apache 2.0처럼 명확하게 확인되지는 않았습니다. 사용자의 요구사항 중 \\'상업적 이용 가능한 라이선스\\'가 중요한 기준이므로, 이 점에서는 Mochi-1이 더 확실한 선택일 수 있습니다.\\n\\n결론적으로, 오픈 소스이며 상업적 이용이 명확히 허용되는 라이선스를 가진 고품질 동영상 생성 모델로는 현재 Mochi-1이 가장 적합한 것으로 판단됩니다. 이용을 원하시면 Mochi-1의 공식 채널을 통해 상세한 사용법과 기술 문서를 확인하시기 바랍니다.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'models/gemini-2.5-flash-preview-04-17', 'safety_ratings': []}, id='run-f63f1ba7-24bc-4e3e-88e1-153f0d2af536-0', usage_metadata={'input_tokens': 3957, 'output_tokens': 2033, 'total_tokens': 7105, 'input_token_details': {'cache_read': 0}})]}\n","################# 응답 #################\n","AI 응답 생각하는 과정:\n","\n","1.  **사용자 요청 분석:** 사용자는 최신 오픈 소스 동영상 생성 AI 모델 중 애니메이션 스타일의 고품질 동영상을 상업적으로 이용 가능한 라이선스로 생성할 수 있는 모델을 찾고 있습니다. 모델의 정밀도(품질, 프롬프트 준수 등)와 이용 방법도 알고 싶어 합니다.\n","\n","2.  **필요한 정보 식별:**\n","    *   최신 오픈 소스 동영상 생성 AI 모델 목록.\n","    *   각 모델의 애니메이션 스타일 생성 능력 및 품질.\n","    *   각 모델의 라이선스 (상업적 이용 가능 여부).\n","    *   각 모델의 정밀도 (품질, 프롬프트 준수, 해상도, 프레임 속도 등).\n","    *   가장 고성능인 모델 식별 (위 기준 종합).\n","    *   선택된 모델의 이용 방법.\n","\n","3.  **검색 전략 수립:** 사용자의 요청에 맞춰 키워드를 조합하여 검색합니다.\n","    *   키워드: \"latest open source video generation AI anime high quality commercial use\"\n","    *   검색 깊이: 상세한 정보를 위해 \"advanced\"\n","    *   시간 범위: \"최신\" 정보를 위해 \"year\"\n","\n","4.  **검색 실행:** `tavily_search` 툴을 사용하여 검색을 수행합니다.\n","    *   `print(default_api.tavily_search(query = \"latest open source video generation AI anime high quality commercial use\", search_depth = \"advanced\", time_range = \"year\"))`\n","\n","5.  **검색 결과 분석:** 검색 결과를 검토하여 각 모델에 대한 정보를 추출합니다.\n","    *   **Hunyuan Video (Tencent):** 오픈 소스, 13B 파라미터, 고품질 시네마틱 (실사/가상 스타일), 720p 해상도, 텍스트-비디오 정렬 및 모션 다양성 우수. 강력한 오픈 소스 중 하나로 언급됨. 상업적 이용 라이선스는 명확히 언급되지 않음.\n","    *   **Mochi-1 (Genmo AI):** 오픈 소스, 10B 파라미터, 30fps 부드러운 모션, 강력한 프롬프트 준수. Apache 2.0 라이선스 (상업적 이용 가능). 연구, 제품 개발, 창의적 표현 등에 적합하다고 언급됨.\n","    *   **Hailuo AI:** 카툰 스타일 템플릿, Director Mode. 플랫폼 형태. 오픈 소스 모델 자체인지는 불분명. 상업적 이용 가능성 언급 (무료/유료).\n","    *   **PixVerse AI, Vidu AI:** 상업적 이용 가능성 언급. 플랫폼 형태일 가능성 높음. 오픈 소스 모델인지는 불분명.\n","    *   **Sora, Runway Gen-2, Pika Labs, Stable Video Diffusion:** 언급은 되지만, 오픈 소스 여부, 애니메이션 특화, 상업적 이용 라이선스가 명확히 연결되어 설명되지 않음.\n","    *   **GPT-4o, DALL-E 3:** 이미지 생성 모델. 동영상 생성 요청과는 다름.\n","\n","6.  **최적 모델 선정:** 사용자의 요구사항 (오픈 소스, 애니메이션 스타일, 고품질, 상업적 이용 가능 라이선스, 정밀도)을 모두 만족하는 모델을 찾습니다.\n","    *   Hunyuan과 Mochi-1이 주요 오픈 소스 후보입니다.\n","    *   Hunyuan은 강력하고 고품질이지만, 상업적 이용 라이선스가 검색 결과에서 명확히 확인되지 않았습니다.\n","    *   Mochi-1은 오픈 소스이며, Apache 2.0 라이선스로 상업적 이용이 명시적으로 가능합니다. 30fps 모션과 강력한 프롬프트 준수는 정밀도 측면에서 긍정적입니다. 애니메이션 스타일에 특화되었다는 명시는 없지만, \"창의적 표현\"에 적합하다는 설명과 텍스트 프롬프트 기반이라는 점에서 다양한 스타일 시도가 가능할 것으로 보입니다.\n","    *   따라서 상업적 이용 가능 라이선스가 명확한 Mochi-1이 현재 검색 결과만으로는 가장 적합한 모델로 판단됩니다.\n","\n","7.  **선택된 모델 정보 정리:** Mochi-1에 대한 정보를 종합합니다.\n","    *   모델명: Mochi-1 (Genmo AI 개발)\n","    *   특징: 오픈 소스, 100억(10B) 파라미터, 30fps 부드러운 모션, 강력한 프롬프트 준수.\n","    *   라이선스: Apache 2.0 (상업적 이용 가능).\n","    *   정밀도: 30fps 모션, 강력한 프롬프트 준수, 고품질 동영상 생성 가능.\n","    *   이용 방법: 텍스트 프롬프트 기반으로 동영상 생성. 공식 웹사이트(mochi1ai.com) 또는 관련 GitHub/문서 참고 필요. 로컬 설치 가능성도 언급됨.\n","\n","8.  **응답 구성:** 사용자에게 조사 결과를 바탕으로 답변을 작성합니다.\n","    *   조사 결과, 현재 시점에서 사용자의 요구사항(오픈 소스, 고품질, 상업적 이용 가능)에 가장 부합하는 모델은 Mochi-1임을 알립니다.\n","    *   Mochi-1의 특징과 장점(오픈 소스, Apache 2.0 라이선스, 30fps, 프롬프트 준수)을 설명합니다.\n","    *   정밀도 측면에서 Mochi-1의 강점을 언급합니다.\n","    *   이용 방법은 텍스트 프롬프트 기반이며, 자세한 내용은 공식 웹사이트나 관련 문서를 참고해야 함을 안내합니다.\n","    *   Hunyuan Video도 강력한 오픈 소스 모델이지만, 상업적 이용 라이선스 정보가 Mochi-1만큼 명확하지 않음을 덧붙여 비교 정보를 제공합니다.\n","    *   애니메이션 스타일에 특화된 모델은 아니지만, 텍스트 프롬프트와 창의적 표현 기능을 통해 애니메이션 스타일 구현이 가능할 수 있음을 시사합니다.\n","\n","9.  **한국어 번역 및 다듬기:** 작성된 내용을 자연스러운 한국어로 번역하고 사용자 친화적으로 다듬습니다.최신 오픈 소스 동영상 생성 AI 모델 중 애니메이션풍의 고품질 동영상을 상업적으로 이용 가능한 라이선스로 생성할 수 있는 모델을 조사한 결과, 현재 시점에서 가장 주목할 만한 모델은 **Mochi-1**입니다.\n","\n","**Mochi-1 (Genmo AI 개발)**\n","\n","*   **특징:** Mochi-1은 100억(10B) 개의 파라미터를 가진 오픈 소스 텍스트-투-비디오 모델입니다. 특히 30 프레임/초(fps)의 부드러운 모션과 텍스트 프롬프트에 대한 강력한 준수 능력이 강점입니다.\n","*   **정밀도:** 고품질 동영상 생성을 목표로 하며, 특히 모션의 자연스러움과 사용자의 입력(프롬프트)을 정확하게 반영하는 데 중점을 둡니다. 애니메이션 스타일에 특화되었다고 명시되어 있지는 않지만, 강력한 프롬프트 준수와 창의적 표현 기능을 통해 다양한 스타일의 동영상 생성이 가능할 것으로 보입니다.\n","*   **라이선스:** Mochi-1은 Apache 2.0 라이선스로 제공됩니다. 이 라이선스는 상업적 이용을 포함하여 매우 자유로운 사용을 허용합니다. 따라서 상업적 목적으로 생성된 동영상을 활용하는 데 문제가 없습니다.\n","*   **이용 방법:** 기본적으로 텍스트 프롬프트를 입력하여 원하는 동영상을 생성하는 방식입니다. 모델 자체를 다운로드하여 로컬 환경에 설치하거나, Genmo AI 등 관련 플랫폼을 통해 접근할 수 있습니다. 자세한 이용 방법이나 설치 가이드는 Mochi-1의 공식 웹사이트(mochi1ai.com)나 관련 GitHub 저장소를 참고하시는 것이 가장 정확합니다.\n","\n","**다른 모델과의 비교:**\n","\n","Hunyuan Video (Tencent 개발) 역시 130억(13B) 파라미터의 강력한 오픈 소스 모델로 언급되며, 고품질 시네마틱 동영상 생성에 뛰어나고 720p 해상도를 지원합니다. 하지만 검색 결과만으로는 Hunyuan Video의 상업적 이용 라이선스가 Mochi-1의 Apache 2.0처럼 명확하게 확인되지는 않았습니다. 사용자의 요구사항 중 '상업적 이용 가능한 라이선스'가 중요한 기준이므로, 이 점에서는 Mochi-1이 더 확실한 선택일 수 있습니다.\n","\n","결론적으로, 오픈 소스이며 상업적 이용이 명확히 허용되는 라이선스를 가진 고품질 동영상 생성 모델로는 현재 Mochi-1이 가장 적합한 것으로 판단됩니다. 이용을 원하시면 Mochi-1의 공식 채널을 통해 상세한 사용법과 기술 문서를 확인하시기 바랍니다.\n","질문을 입력해주세요: exit\n","종료하겠습니다.\n"]}],"source":["#6\n","\n","while True:\n","    query = input(\"질문을 입력해주세요: \")\n","    if query.lower() in [\"exit\", \"quit\"]:\n","        print(\"종료하겠습니다.\")\n","        break\n","\n","    print(\"################# 질문 #################\")\n","    print(\"질문:\", query)\n","\n","    input_query = [HumanMessage(\n","            [\n","                {\n","                    \"type\": \"text\",\n","                    \"text\": f\"{query}\"\n","                },\n","            ]\n","        )]\n","\n","    response = graph.invoke({\"messages\": input_query} ,config={\"configurable\": {\"thread_id\": uuid.uuid4()}})\n","\n","    print(\"response: \", response)\n","    print(\"################# 응답 #################\")\n","    print(\"AI 응답\",response[\"messages\"][-1].content)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fjS00diXjzzn"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}